[
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Tutorial for LBCNet pacakge",
    "section": "",
    "text": "Welcome to the LBCNet tutorial! This guide provides a detailed introduction to the LBCNet package and demonstrates its use in causal inference analyses. LBCNet stands for Local Balance with Calibration implemented by Neural Networks. The package offers a set of tools for estimating propensity scores in a nonparametric way, using neural networks, and for evaluating the quality of these estimates through intuitive diagnostics and visualizations.\nLBCNet has two main objectives. First, it aims to provide accurate propensity score estimation to support causal effect estimation, including the average treatment effect (ATE) and the average treatment effect on the treated (ATT). Second, it offers diagnostic tools to assess the quality of the estimated propensity scores. These diagnostics include evaluations of the propensity score distributions, covariate distributions, and checks for local balance and local calibration. To aid interpretation, LBCNet also provides several visualization tools, such as mirror histograms, calibration plots, and local balance plots.\nPropensity score methods have become a cornerstone in addressing confounding in observational studies. The concept of propensity scores was introduced by Rosenbaum and Rubin (1983) as the probability of treatment assignment conditional on a set of observed covariates. Under the strong ignorability assumption, adjusting for the propensity score allows for unbiased estimation of treatment effects. A key property of the propensity score is its balancing property, which ensures that, given the propensity score, the distribution of covariates is similar between treatment and control groups. Proper estimation of propensity scores helps reduce covariate imbalance, which is a primary source of bias in causal inference.\nLBCNet addresses the critical importance of covariate balance by introducing two fundamental conditions: local balance and local calibration. Local balance ensures that covariates are balanced across a dense grid of propensity scores, while local calibration guarantees that the balancing scores correspond to true propensity scores. To achieve these goals, LBCNet leverages neural networks, which are capable of capturing complex, nonlinear relationships between covariates. Neural networks are particularly suitable for this task due to their flexibility, ability to model high-dimensional data, and efficiency through parallel processing.\nThis tutorial walks you through the process of setting up LBCNet, including options for using system Python and virtual environments via the reticulate package. It then demonstrates a complete analysis on a public lalonde data set from sbw package (Zubizarreta, 2024), with detailed instructions on how to choose parameters, interpret diagnostic results, and evaluate balance. The tutorial also provides guidance on achieving optimal balance and reliable causal estimates, along with notes on function arguments and practical tips for users.\nSupport for multiple treatment groups is currently under development and will be included in a future release of the package."
  },
  {
    "objectID": "tutorial.html#introduction",
    "href": "tutorial.html#introduction",
    "title": "Tutorial for LBCNet pacakge",
    "section": "",
    "text": "Welcome to the LBCNet tutorial! This guide provides a detailed introduction to the LBCNet package and demonstrates its use in causal inference analyses. LBCNet stands for Local Balance with Calibration implemented by Neural Networks. The package offers a set of tools for estimating propensity scores in a nonparametric way, using neural networks, and for evaluating the quality of these estimates through intuitive diagnostics and visualizations.\nLBCNet has two main objectives. First, it aims to provide accurate propensity score estimation to support causal effect estimation, including the average treatment effect (ATE) and the average treatment effect on the treated (ATT). Second, it offers diagnostic tools to assess the quality of the estimated propensity scores. These diagnostics include evaluations of the propensity score distributions, covariate distributions, and checks for local balance and local calibration. To aid interpretation, LBCNet also provides several visualization tools, such as mirror histograms, calibration plots, and local balance plots.\nPropensity score methods have become a cornerstone in addressing confounding in observational studies. The concept of propensity scores was introduced by Rosenbaum and Rubin (1983) as the probability of treatment assignment conditional on a set of observed covariates. Under the strong ignorability assumption, adjusting for the propensity score allows for unbiased estimation of treatment effects. A key property of the propensity score is its balancing property, which ensures that, given the propensity score, the distribution of covariates is similar between treatment and control groups. Proper estimation of propensity scores helps reduce covariate imbalance, which is a primary source of bias in causal inference.\nLBCNet addresses the critical importance of covariate balance by introducing two fundamental conditions: local balance and local calibration. Local balance ensures that covariates are balanced across a dense grid of propensity scores, while local calibration guarantees that the balancing scores correspond to true propensity scores. To achieve these goals, LBCNet leverages neural networks, which are capable of capturing complex, nonlinear relationships between covariates. Neural networks are particularly suitable for this task due to their flexibility, ability to model high-dimensional data, and efficiency through parallel processing.\nThis tutorial walks you through the process of setting up LBCNet, including options for using system Python and virtual environments via the reticulate package. It then demonstrates a complete analysis on a public lalonde data set from sbw package (Zubizarreta, 2024), with detailed instructions on how to choose parameters, interpret diagnostic results, and evaluate balance. The tutorial also provides guidance on achieving optimal balance and reliable causal estimates, along with notes on function arguments and practical tips for users.\nSupport for multiple treatment groups is currently under development and will be included in a future release of the package."
  },
  {
    "objectID": "tutorial.html#setup-configuring-python-for-lbcnet",
    "href": "tutorial.html#setup-configuring-python-for-lbcnet",
    "title": "Tutorial for LBCNet pacakge",
    "section": "Setup: Configuring Python for LBCNet",
    "text": "Setup: Configuring Python for LBCNet\nBefore using LBC-Net, you need to configure a Python environment. This environment runs the neural network model behind LBC-Net’s nonparametric propensity score estimation. The package uses the reticulate package to manage Python environments and packages from within R. The key function for managing this setup is setup_lbcnet().\nsetup_lbcnet() configures the Python environment required by LBC-Net. It checks for Python availability, ensures necessary Python packages (e.g., Torch) are installed, and manages virtual environments. You can call setup_lbcnet() directly before running lbc_net(), or let lbc_net() call it automatically during model fitting by passing arguments through setup_lbcnet_args.\nHow it works:\n\nIf Python has not been configured, setup_lbcnet() will Automatically create a virtual environment named “r-lbcnet” by default (if create_if_missing = TRUE). And install the required Python packages.\nIf you already have a virtual environment or want to use system Python, you can customize how LBC-Net connects to Python.\n\n\nOption 1: Virtual Environment (Recommended)\nThis is the default and safest setup, creating a dedicated Python environment for LBCNet. If you have not set up reticulate before, simply run:\n\nlibrary(LBCNet)\n\n# Automatically creates and sets up \"r-lbcnet\" virtual environment\nsetup_lbcnet(create_if_missing = TRUE)\n\nThis will create a virtual environment named “r-lbcnet” if it doesn’t exist and install all necessary Python packages (TensorFlow, etc.). Then it activates and uses the virtual environment.\nIf you want to manually create and control the virtual environment, you can do:\n\nlibrary(reticulate)\n\n# Create the virtual environment (only run once)\nvirtualenv_create(\"r-lbcnet\")\n\n# Activate the virtual environment in your R session\nuse_virtualenv(\"r-lbcnet\", required = TRUE)\n\nOnce this is done, lbc_net() will automatically detect and use the environment “r-lbcnet”. If you have multiple virtual environments, specify the environment explicitly via setup_lbcnet(envname = \"r-lbcnet\"). In addition, you can also pass the environment name when calling lbc_net() by using the setup_lbcnet_args argument:\n\nlbc_net(\n  data = mydata,\n  formula = Tr ~ X1 + X2 + X3,\n  setup_lbcnet_args = list(envname = \"r-lbcnet\")\n)\n\n\n\nOption 2: System Python\nIf you prefer to use an existing system Python installation instead of virtualenv or Conda, you can specify use_system_python = TRUE and point to your Python executable. You can use the following code to find the available Python executables on your system:\n\nlibrary(LBCNet)\n\n# Discover available Python environments\navailable_pythons &lt;- unique(c(\n  Sys.which(\"python\"),\n  Sys.which(\"python3\"),\n  reticulate::py_discover_config()$python\n))\n\n# Clean up and display results\navailable_pythons &lt;- available_pythons[nzchar(available_pythons)]\nprint(available_pythons)\n\nNote: Sys.which() returns only the first Python executable found on your system. If this does not match the Python path you want to use, you should specify the correct path manually. If you have a specific Python executable path you want to use, do this:\n\npath &lt;- \"C:/Users/mpeng1/AppData/Local/Programs/Python/Python311/python.exe\" ## change it to your path\n\n# Set up LBCNet to use system Python\nsetup_lbcnet(use_system_python = TRUE, system_python_path = path)\n\nAlternatively, you can specify it when calling lbc_net():\n\nlbc_net(\n  data = mydata,\n  formula = Tr ~ X1 + X2 + X3,\n  setup_lbcnet_args = list(\n    use_system_python = TRUE,\n    system_python_path = \"C:/Users/mpeng1/AppData/Local/Programs/Python/Python311/python.exe\"\n  )\n)\n\n\n\nOption 3: Conda Environment\nIf you prefer Conda environments, you can specify use_conda = TRUE in setup_lbcnet() and lbc_net() to manage environments through Conda instead of virtualenv. For more details on Conda environments in R, refer to the official Reticulate Documentation.\nIf you encounter issues, try reticulate::py_discover_config() to see which Python environment is active."
  },
  {
    "objectID": "tutorial.html#implementing-lbc-net-on-the-lalonde-dataset-ate-estimation",
    "href": "tutorial.html#implementing-lbc-net-on-the-lalonde-dataset-ate-estimation",
    "title": "Tutorial for LBCNet pacakge",
    "section": "Implementing LBC-Net on the lalonde Dataset (ATE Estimation)",
    "text": "Implementing LBC-Net on the lalonde Dataset (ATE Estimation)\nThe dataset originates from the National Supported Work (NSW) Demonstration, an experimental program designed to evaluate the impact of employment training on future earnings. The treatment assignment indicator (treatment) specifies whether an individual received the job training (1 = treated, 0 = control). The dataset includes pre-treatment covariates: age (in years), education (years of schooling), black (1 if Black, 0 otherwise), hispanic (1 if Hispanic, 0 otherwise), married (1 if married, 0 otherwise), nodegree (1 if the individual has no high school diploma), re74 (real earnings in 1974), and re75 (real earnings in 1975). The outcome variable is re78, which records real earnings in 1978. The Lalonde dataset includes 614 observations, consisting of 185 treated and 429 control subjects, with a total of 10 variables.\nIn this example, we use the lbc_net() function to estimate propensity scores for the binary treatment based on the pre-treatment covariates listed above. We run lbc_net() with its default parameters and provide an explanation of key options that users may want to modify depending on their analysis.\nFirst, we fit the LBC-Net model to estimate the propensity score for receiving abciximab treatment. We use the covariates as predictors in the formula.\n\nlibrary(sbw)\ndata(\"lalonde\")\n\nlibrary(LBCNet)\nlbc_net.fit &lt;- lbc_net(\n  data = lalonde,\n  formula = treatment ~ age + education + black + hispanic + married + nodegree + re74 + re75,\n  max_epochs = 15000,\n  rho = 0.4\n)\n\n⚠️ Stopping criterion not met at max epochs. Try increasing `max_epochs` or adjusting `lsd_threshold` for better convergence.\n✅ LBC-Net training completed successfully.\n\n\nHere, we adjust the lbc_net() parameters to account for the small sample size and limited overlap observed in the Lalonde dataset. The mirror histogram from mirror_hist() shows poor overlap between treated and control groups, making balance harder to achieve. To address this, we increase the training iterations to 15,000 epochs (max_epochs = 15000) and expand the local neighborhood size to 40% of the sample (rho = 0.4). These adjustments give the model more time to optimize and ensure sufficient data points within each local region to improve balance.\nAfter fitting the LBC-Net model using lbc_net(), the next step is to evaluate its performance and the quality of the estimated propensity scores.\nThe print() function provides a quick summary of the training process, including the training loss, local balance metrics, and other key indicators. For detailed results, such as causal effect estimates and covariate balance summaries, use the summary() function.\nIn this example, we use summary() to obtain estimates of the ATE on six-month survival. Since the outcome variable is not specified by default, we pass it explicitly as the argument Y. In this case, the outcome is binary (survival status), but we continue to compute the ATE. For survival outcomes with time-to-event data, you can alternatively apply a weighted Cox proportional hazards model using the propensity score weights from LBCNet.\n\nsummary(lbc_net.fit, Y = lalonde$re78)\n\nCall:\n treatment ~ age + education + black + hispanic + married + nodegree +      re74 + re75 \nSample Size: 614  | Number of Covariates: 8 \nTreated: 185  | Control: 429 \n\n--- Losses ---\nBalance Loss:      0.0158\nCalibration Loss:  0.7658\nTotal Loss:        0.7815\n\n--- Local Balance (LSD) % ---\nMax LSD:   9.0997\nMean LSD:  0.6369\n\n--- Global Standardized Differences (GSD) % ---\nCovariate        Pre-GSD     Post-GSD \n--------------------------------------- \nage             -22.5450      -1.2933 \neducation         4.2090       0.9827 \nblack           163.8478       0.7593 \nhispanic        -25.8951      -0.3112 \nmarried         -68.8767      -2.6840 \nnodegree         23.2018       1.0334 \nre74            -56.2210      -2.1712 \nre75            -28.6199      -2.0824 \n\n--- Treatment Effect Estimate ---\nATE: -88.2016\n\n\nBy default, summary() computes the ATE using the inverse probability of treatment weights (IPTW) derived from the estimated propensity scores. If you are working with survival outcomes (time-to-event data), you can use a weighted Cox proportional hazards model by applying the weights coxph(Surv(time, event) ~ abcix, data = lindner, weights = lbc_net.fit$weights).\nThe summary() output also includes a covariate balance table, which reports the standardized mean differences before and after weighting, and a global balance metric, the Global Standardized Difference (GSD). The GSD summarizes the overall covariate imbalance across all variables, expressed as a percentage. You can extract these tables from the summary output using summary_out$balance_table (a data frame) and summary_out$gsd.\nTo evaluate the performance of LBC-Net relative to traditional methods, we can compare its global balance (GSD) with that obtained from logistic regression propensity scores. Below is an example of how to fit a logistic regression model, extract the predicted propensity scores, and compute the GSD using the gsd() function.\n\nlog.fit &lt;- glm(\n  treatment ~ age + education + black + hispanic + married + nodegree + re74 + re75,\n  data = lalonde,\n  family = binomial()\n)\n\nps_log &lt;- log.fit$fitted.values\nTr &lt;- lalonde$treatment\nZ &lt;- lalonde[, c(\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re74\", \"re75\")]\n\n## Compute GSD\ngsd_log &lt;- gsd(\n  Z = Z,\n  Tr = Tr,\n  ps = ps_log\n)\n\ngsd_log\n\n       age  education      black   hispanic    married   nodegree       re74 \n-14.947443  12.094698  10.175575   1.447039 -19.351822 -11.262428 -25.978241 \n      re75 \n-16.354046 \n\n## Calculate ATE\nwt_log &lt;- 1/(ps_log*Tr+(1-Tr)*(1-ps_log))\nest_effect(Y = lalonde$re78, Tr = Tr, wt = wt_log)\n\n[1] 224.6763"
  },
  {
    "objectID": "tutorial.html#evaluating-the-estimated-propensity-scores",
    "href": "tutorial.html#evaluating-the-estimated-propensity-scores",
    "title": "Tutorial for LBCNet pacakge",
    "section": "Evaluating the Estimated Propensity Scores",
    "text": "Evaluating the Estimated Propensity Scores\nAfter fitting the LBC-Net model and obtaining propensity scores, the next step is to evaluate how well these scores satisfy the key assumptions required for causal inference, such as overlap and covariate balance. This section demonstrates how to use LBC-Net’s diagnostic plots to assess the quality of the estimated scores.\nThe mirror histogram shows the distribution of propensity scores for treated and control groups. It helps assess the overlap (common support) assumption, which is critical for valid causal comparisons. You can generate this plot directly from the fitted lbc_net object as follows:\n\nmirror_hist(lbc_net.fit)\n\n\n\n\n\n\n\n\nWhile the sample size is relatively small, there is reasonable overlap between groups across much of the propensity score range. In larger datasets, this overlap may be even clearer, but the current plot suggests the assumption is adequately met.\nThe mirror_hist() function can also be used with any set of propensity scores by specifying ps and Tr. For example, with propensity scores from a logistic regression model mirror_hist(ps = ps_log, Tr = Tr).\nThe plot_cov_bal() function shows the distribution of a specific covariate in the treated and control groups, both before and after weighting. This allows you to visually assess whether LBC-Net has improved covariate balance after applying weights. In this example, we examine the balance of the covariate height:\n\nplot_cov_bal(lbc_net.fit, cov = \"education\", use_weights = TRUE)\n\n\n\n\n\n\n\n\nBy default, the plot displays the weighted distribution using kernel density estimation. If you prefer to view the unweighted distribution, you can set use_weights = FALSE. Additionally, you can display the distribution as histograms instead of density plots by using plot_type = \"hist\".\n\nLocal Calibration and Local Balance\nAfter fitting the LBC-Net model, it is important to evaluate whether the estimated propensity scores satisfy key theoretical properties: calibration and covariate balance. These evaluations help assess the quality of the propensity score model and its ability to support valid causal inference.\nThe local calibration check assesses whether the estimated propensity scores accurately reflect the probability of treatment assignment. We use the plot_calib() function to visualize calibration. A well-calibrated model will have its fitted line closely follow the 45-degree line, indicating that predicted probabilities match observed treatment rates across the score range.\n\nplot_calib(lbc_net.fit)\n\n\n\n\n\n\n\n\nIn this case, due to the small sample size and limited overlap in the Lalonde dataset, we observe some deviation from the 45-degree line, particularly in the middle range of the propensity scores. This suggests that while LBCNet performs reasonably well, achieving perfect calibration in smaller samples with poor overlap remains challenging.\nThe local balance check evaluates whether covariates are balanced between treatment groups across the range of propensity scores. We use the lsd() function to calculate the Local Standardized Differences (LSD) and summarize them across covariates.\n\nlsd.fit &lt;- lsd(lbc_net.fit)\nsummary(lsd.fit)\n\nCall:\n function (x, ...)  UseMethod(\"formula\") \nSample Size: 614  | Number of Covariates: 8 \nTreated: 185  | Control: 429 \nEstimand: ATE (Average Treatment Effect) \n\n--- Local Balance (LSD) % ---\nMax LSD:   9.0997\nMean LSD:  0.6369\n\nCovariates    LSD % \n-------------------- \nage          0.9588 \neducation    0.3853 \nblack        0.6747 \nhispanic     0.2941 \nmarried      0.7915 \nnodegree     0.4263 \nre74         0.8330 \nre75         0.7317 \n\nplot(lsd.fit)\n\n\n\n\n\n\n\n\nThe summary(lsd.fit) function provides the mean LSD for each covariate, while plot(lsd.fit) visualizes local balance across the entire score range. The default plot shows boxplots summarizing the variation in local balance across all covariates (cov = “all”). To focus on a specific covariate, such as age, you can specify it directly with cov = \"age\". If you prefer to remove the boxplots and focus on the local balance curves, you can suppress them by setting box.loc = NULL. In this example, LBCNet maintains local standardized differences generally under \\(5\\%\\) across the full range of propensity scores, suggesting good local balance.\nFor comparison, we can evaluate the local balance and calibration of propensity scores estimated from a traditional logistic regression model.\n\nplot_calib(Tr = Tr, ps = ps_log)\n\n\n\n\n\n\n\nlsd.fit.log &lt;- lsd(Z = Z, Tr = Tr, ps = ps_log)\nsummary(lsd.fit.log)\n\nCall:\n function (x, ...)  UseMethod(\"formula\") \nSample Size: 614  | Number of Covariates: 8 \nTreated: 185  | Control: 429 \nEstimand: ATE (Average Treatment Effect) \n\n--- Local Balance (LSD) % ---\nMax LSD:   77.7346\nMean LSD:  10.2577\n\nCovariates    LSD % \n-------------------- \nage         16.3696 \neducation    9.0942 \nblack        6.0572 \nhispanic     2.9699 \nmarried     13.7013 \nnodegree    12.7773 \nre74        11.7533 \nre75         9.3384 \n\nplot(lsd.fit.log)\n\n\n\n\n\n\n\n\nCompared to LBC-Net, logistic regression shows larger global and local imbalance, with higher LSD values and more severe deviations in the calibration plot. These results highlight the advantage of LBC-Net in achieving better local balance and calibration, particularly in datasets with challenging overlap and sample size conditions."
  },
  {
    "objectID": "tutorial.html#reference",
    "href": "tutorial.html#reference",
    "title": "Tutorial for LBCNet pacakge",
    "section": "Reference",
    "text": "Reference\nRosenbaum, P. R. and Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1):41–55.\nZubizarreta J, Li Y, Kim K (2024). sbw: Stable Balancing Weights for Causal Inference and Missing Data. R package version 1.1.9, https://CRAN.R-project.org/package=sbw."
  },
  {
    "objectID": "tutorial.html#contribute-and-feedback",
    "href": "tutorial.html#contribute-and-feedback",
    "title": "Tutorial for LBCNet pacakge",
    "section": "Contribute and Feedback",
    "text": "Contribute and Feedback\nWe welcome contributions, feedback, and suggestions!\n- Report bugs or request features on our GitHub Issues page.\n- Fork the repository and submit pull requests to help improve LBCNet!"
  },
  {
    "objectID": "example.html",
    "href": "example.html",
    "title": "Quick Simulated Example with LBCNet",
    "section": "",
    "text": "This example demonstrates how to apply LBCNet on a simulated dataset inspired by the misspecified propensity score model from Kang & Schafer (2007). Our goal is to estimate the mean outcome, assess covariate balance, and evaluate propensity score calibration using local system Python."
  },
  {
    "objectID": "example.html#purpose-of-this-example",
    "href": "example.html#purpose-of-this-example",
    "title": "Quick Simulated Example with LBCNet",
    "section": "",
    "text": "This example demonstrates how to apply LBCNet on a simulated dataset inspired by the misspecified propensity score model from Kang & Schafer (2007). Our goal is to estimate the mean outcome, assess covariate balance, and evaluate propensity score calibration using local system Python."
  },
  {
    "objectID": "example.html#simulate-the-data",
    "href": "example.html#simulate-the-data",
    "title": "Quick Simulated Example with LBCNet",
    "section": "Simulate the Data",
    "text": "Simulate the Data\nWe simulate data where the true propensity score model differs from the one used in the analysis, representing a challenging scenario for causal inference (misspecified propensity score model).\n\n# Load required packages\nlibrary(MASS)\n\n# Set seed for reproducibility\nset.seed(123456)\n\n# Define sample size\nn &lt;- 5000\n\n# Generate true covariates from a multivariate normal distribution\nZ &lt;- MASS::mvrnorm(n, mu = rep(0, 4), Sigma = diag(4))\n\n# Generate true propensity scores\nprop &lt;- 1 / (1 + exp(Z[,1] - 0.5 * Z[,2] + 0.25 * Z[,3] + 0.1 * Z[,4]))\n\n# Assign treatment based on propensity scores\nTr &lt;- rbinom(n, 1, prop)\n\n# Generate continuous outcome (correct model)\nY &lt;- 210 + 27.4 * Z[,1] + 13.7 * Z[,2] + 13.7 * Z[,3] + 13.7 * Z[,4] + rnorm(n)\n\n# Create a set of covariates for estimation (misspecified model)\nX &lt;- cbind(\n  exp(Z[,1] / 2),\n  Z[,2] * (1 + exp(Z[,1]))^(-1) + 10,\n  ((Z[,1] * Z[,3]) / 25 + 0.6)^3,\n  (Z[,2] + Z[,4] + 20)^2\n)\n\n# Combine data into a data frame\ndata &lt;- data.frame(Y, Tr, X)\ncolnames(data) &lt;- c(\"Y\", \"Tr\", \"X1\", \"X2\", \"X3\", \"X4\")\n\n# Quick look at the data\nhead(data)\n\n         Y Tr        X1        X2        X3       X4\n1 267.0934  1 2.0995290 10.136751 0.1936739 465.4067\n2 211.1973  1 1.0944490 10.811059 0.2031783 462.5301\n3 190.5548  1 1.1113093  9.313208 0.2168326 327.9726\n4 209.1748  1 0.9292040 10.001453 0.2145796 403.6159\n5 198.9068  1 0.4234368 10.261615 0.2123729 508.9887\n6 235.8486  0 0.7080015 11.445936 0.2109414 529.2390"
  },
  {
    "objectID": "example.html#set-up-python-environment-using-a-virtual-environment",
    "href": "example.html#set-up-python-environment-using-a-virtual-environment",
    "title": "Quick Simulated Example with LBCNet",
    "section": "Set Up Python Environment Using a Virtual Environment",
    "text": "Set Up Python Environment Using a Virtual Environment\nIn this example, we set up LBCNet to run in a Python virtual environment called \"r-lbcnet\".\nUsing a virtual environment ensures the Python packages needed for LBCNet are installed and isolated from other projects.\n\nlibrary(LBCNet)\n\n# Set up LBCNet to use a virtual environment named \"r-lbcnet\"\nsetup_lbcnet(\n  envname = \"r-lbcnet\",       # Name of the virtual environment\n  create_if_missing = TRUE   # Set to TRUE if you want LBCNet to create the environment automatically if it doesn't exist\n)\n\nHere, envname = \"r-lbcnet\" specifies the name of the Python virtual environment and create_if_missing = FALSE means LBCNet will automatically create a new virtual environment and install the necessary Python dependencies (like torch) if it doesn’t already exist."
  },
  {
    "objectID": "example.html#fit-the-lbc-net-model",
    "href": "example.html#fit-the-lbc-net-model",
    "title": "Quick Simulated Example with LBCNet",
    "section": "Fit the LBC-Net Model",
    "text": "Fit the LBC-Net Model\nEstimate propensity scores using LBC-Net with the covariates X1, X2, X3, X4.\n\n# Fit the LBC-Net model\nlbc_net.fit &lt;- lbc_net(\n  data = data,\n  formula = Tr ~ X1 + X2 + X3 + X4\n)\n\nPython is already set up. Skipping `setup_lbcnet()`.\n\n\nCalculating propensity scores for ck/h calculation...\n\n\n✅ Stopping early at epoch 1200 (rolling average max LSD &lt; 2.0%)\n✅ LBC-Net training completed successfully.\n\n# Print the model fit object\nprint(lbc_net.fit)\n\nCall: Tr ~ X1 + X2 + X3 + X4 \nSample Size: 5000  | Treated: 2466  | Control: 2534 \nEstimand: ATE (Average Treatment Effect) \n\n--- Training Results ---\nFinal Loss Value: 1.9297 \nMax LSD: 1.06% \nMean LSD: 0.37% \n\n--- Model Hyperparameters ---\nHidden Layers: 1 | Hidden Units: 100\nVAE Learning Rate: 0.010 | LBC-Net Learning Rate: 0.050\nWeight Decay: 1.0e-05 | Balance Lambda: 1.00\nKernel: \"gaussian\" \n\n--- Stopping Criteria ---\nLSD Threshold: 2.00% | Rolling Window: 5\nMax Training Epochs: 5000\n\nUse summary(object) for a full model summary."
  },
  {
    "objectID": "example.html#evaluate-propensity-score-estimation-performance",
    "href": "example.html#evaluate-propensity-score-estimation-performance",
    "title": "Quick Simulated Example with LBCNet",
    "section": "Evaluate Propensity Score Estimation Performance",
    "text": "Evaluate Propensity Score Estimation Performance\nSummarize the model and visualize the estimated propensity scores.\n\n# Summarize the fitted model with outcome Y\nsummary(lbc_net.fit, Y = data$Y, type = \"Y\")\n\nCall:\n Tr ~ X1 + X2 + X3 + X4 \nSample Size: 5000  | Number of Covariates: 4 \nTreated: 2466  | Control: 2534 \n\n--- Losses ---\nBalance Loss:      0.0156\nCalibration Loss:  1.9141\nTotal Loss:        1.9297\n\n--- Local Balance (LSD) % ---\nMax LSD:   1.0640\nMean LSD:  0.3661\n\n--- Global Standardized Differences (GSD) % ---\nCovariate      Pre-GSD     Post-GSD \n-------------------------------- \nX1       -78.1284      -0.4820 \nX2        40.5772       0.4233 \nX3        -5.9774      -0.2298 \nX4        21.7461       0.3807 \n\n--- Treatment Effect Estimate ---\nY: 209.1125\n\n# Mirror histogram for covariate distribution balance\nmirror_hist(lbc_net.fit)\n\n\n\n\n\n\n\n# Calibration plot to assess model calibration\nplot_calib(lbc_net.fit)"
  },
  {
    "objectID": "example.html#evaluate-covariate-balance",
    "href": "example.html#evaluate-covariate-balance",
    "title": "Quick Simulated Example with LBCNet",
    "section": "Evaluate Covariate Balance",
    "text": "Evaluate Covariate Balance\n\n# Compute local balance diagnostics\nlsd.fit &lt;- lsd(lbc_net.fit)\n\n# Print and summarize local balance\nprint(lsd.fit)\n\nSample Size: 5000  | Treated: 2466  | Control: 2534 \nEstimand: ATE (Average Treatment Effect) \n\n--- Local Balance (LSD) % ---\nMax LSD: 1.0641 \nMean LSD: 0.366 \n\nKernel: \"gaussian\" \n\nUse summary(object) for a full model summary.\n\nsummary(lsd.fit)\n\nCall:\n function (x, ...)  UseMethod(\"formula\") \nSample Size: 5000  | Number of Covariates: 4 \nTreated: 2466  | Control: 2534 \nEstimand: ATE (Average Treatment Effect) \n\n--- Local Balance (LSD) % ---\nMax LSD:   1.0641\nMean LSD:  0.3660\n\nCovariates   LSD % \n------------- \nX1    0.2592 \nX2    0.4479 \nX3    0.3110 \nX4    0.4461 \n\n# Plot local balance metrics\nplot(lsd.fit)\n\n\n\n\n\n\n\n\nFor a more detailed tutorial, visit our Step-by-Step Tutorial."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Welcome to LBCNet",
    "section": "Introduction",
    "text": "Introduction\nLBCNet is an R package designed to easily estimate propensity scores using advanced deep learning methods (Local Balance with Calibration implemented by Neural Networks) introduced in “A Deep Learning Approach to Nonparametric Propensity Score Estimation with Optimized Covariate Balance”. It provides a user-friendly way to perform robust propensity score analysis while ensuring covariate balance, improving causal inference in observational studies.\n\nWhat is the purpose of LBC-Net?\nThe package aims to provide researchers and analysts with:\n\nNonparametric estimation of propensity scores using neural networks.\nImproved covariate balance, ensuring groups are comparable across a range of covariates\nIntegration of Python and R: Leverage powerful neural network modeling through seamless integration with Python scripts directly within R.\n\n\n\nKey Features\n\nEasy integration of Python within R for running advanced neural network models\nInteractive visualizations that simplify evaluating propensity score distributions and covariate balance:\n\nMirror Histograms (to visualize propensity score distribution)\nLocal Balance Plot (to assess covarite balance)\nHosmer-Lemeshow Plot (to evaluate calibration)\n\nUser-friendly interface making advanced deep-learning methods accessible."
  },
  {
    "objectID": "index.html#installation-instructions",
    "href": "index.html#installation-instructions",
    "title": "Welcome to LBCNet",
    "section": "Installation Instructions",
    "text": "Installation Instructions\n\nInstall LBCNet\ndevtools::install_github(\"MaosenPeng1/LBCNet\")\nOr\nremotes::install_github(\"MaosenPeng1/LBCNet\")\nBefore using the package, users must have Python installed. It is recommended to set up Python using the reticulate package for the first time. Instructions are as follows.\n\n\nInstalling Python\nLBCNet requires Python to be installed on your system. You can download and install Python from the official website:\n\nDownload Python\n\nMake sure to install Python 3.8 - 3.11, as versions 3.12 and above may cause compatibility issues with some dependencies.\n\nVerifying Python Installation\nAfter installing Python, open a terminal or command prompt and check if Python is installed correctly by running:\npython --version\nor\npython3 --version\nIf Python is installed correctly, you should see an output similar to:\nPython 3.10.12\nFor Windows users, ensure that Python is added to the system PATH during installation. If you encounter any issues, refer to the official Python documentation for troubleshooting.\n\n\n\nFirst-Time Setup: Installing and Configuring Reticulate in R\nLBCNet uses the reticulate package to interface between R and Python. The first time you use LBCNet, you must set up reticulate and configure Python. Once the setup is complete, you won’t need to configure it every time.\n\n1. Install reticulate in R\nIf you haven’t installed reticulate yet, run:\ninstall.packages(\"reticulate\")\nFor detailed installation and setup instructions, visit the Reticulate Documentation.\n\n\n2. Verify Python Installation in R\nAfter installing reticulate, load it and check which Python version is detected:\navailable_pythons &lt;- unique(c(\n  Sys.which(\"python\"),\n  Sys.which(\"python3\"),\n  reticulate::py_discover_config()$python\n))\n\navailable_pythons &lt;- available_pythons[nzchar(available_pythons)]  # Remove empty results\nprint(available_pythons)\n\n# Check available virtual and Conda environments\nreticulate::virtualenv_list()\nreticulate::conda_list()\nIf reticulate detects the correct Python version, you can skip the next step. If not, you must manually specify the correct Python path.\n\n\n3. First-Time Python Setup: Choose One of the Following Options\nThere are multiple ways to configure Python for reticulate. Choose one method that best suits your setup.\nOption 1: Use System Python (Recommended for Servers & Clusters) If Python is installed globally on your system, reticulate should detect it automatically. To manually specify the path:\n## Set the Python Path for the Entire R Session \n## Best for: Servers, clusters, and users who manage Python separately.\nSys.setenv(RETICULATE_PYTHON = \"/path/to/python\")  # Adjust based on your system\nreticulate::py_discover_config()\nOr\n## Set Python for the Current R Session Only\n## Best for: Local machines where Python paths may change frequently.\nreticulate::use_python(\"/path/to/python\", required = TRUE)\nreticulate::py_config()\nThis ensures stability by using a known, system-managed Python installation. Using system Python may cause conflicts if other R packages require different dependencies.\nOption 2: Create a Virtual Environment (Recommended) A virtual environment (venv) isolates Python dependencies, ensuring LBCNet runs without conflicts. Create and activate a virtual environment:\nreticulate::virtualenv_create(\"r-lbcnet\")  # Create virtual environment\nreticulate::use_virtualenv(\"r-lbcnet\", required = TRUE)  # Activate virtual environment\nBest for: Ensuring package isolation and avoiding conflicts with other Python versions.\nOption 3: Use a Conda Environment If you have Conda installed, you can use a Conda-managed Python environment.\nreticulate::conda_create(\"r-lbcnet\", packages = c(\"python=3.11\"))\nreticulate::use_condaenv(\"r-lbcnet\", required = TRUE)\nBest for: Users who already use Conda to manage Python dependencies.\n\n\n4. First-Time Installation of Required Python Packages\nOnce Python is configured, you need to install the required dependencies. Run one of the following:\nreticulate::py_install(c(\"torch\", \"numpy\", \"pandas\", \"tqdm\"), envname = \"r-lbcnet\")\nOR\nsystem(\"pip install torch numpy pandas tqdm\")\nVerify the installation:\npy_run_string(\"import numpy; print(numpy.__version__)\")\npy_run_string(\"import torch; print(torch.__version__)\")\nFor detailed package intall instructions, visit the Package Install.\n\n\n5. Common Issues and Fixes\n\nMultiple Python Installations: If you have multiple versions of Python installed, you may need to specify the correct path using use_python().\nAdministrator Privileges: Some installations require running R with administrator privileges to install dependencies.\nDependency Restrictions: Certain Python packages may not work with the latest versions of Python (e.g., Python ≥3.12).\nPython version mismatch: Run py_config() and ensure Python is set to the correct version.\nModule not found (e.g., torch not found): Run py_install(\"torch\") to install missing dependencies or try py_require(\"torch\").\nFailed to initialize Python: Restart your R session (Session &gt; Restart R) and rerun use_virtualenv() or use_condaenv().\n\nIf all commands execute without errors and display package versions, the installation was successful."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Welcome to LBCNet",
    "section": "Getting Started",
    "text": "Getting Started\nExplore the package with our easy-to-follow resources:\n\nSimulated Example: Quick demo to validate the package functions. -Comprehensive Tutorial: Step-by-step detailed usage guide."
  },
  {
    "objectID": "index.html#citation-suggested",
    "href": "index.html#citation-suggested",
    "title": "Welcome to LBCNet",
    "section": "Citation Suggested",
    "text": "Citation Suggested"
  },
  {
    "objectID": "index.html#need-help",
    "href": "index.html#need-help",
    "title": "Welcome to LBCNet",
    "section": "Need Help?",
    "text": "Need Help?\n\nGitHub: LBCNet Repository\n\nEmail: email to contact\n\nWe encourage feedback, issue reporting, and contributions! We’re open to contributions and improvements—visit our GitHub page to report bugs or suggest new features!"
  }
]